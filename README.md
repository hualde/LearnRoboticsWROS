# ğŸ¤– Proyecto Pick and Place con VisiÃ³n - UR5 + Robotiq Gripper

Sistema completo de pick and place guiado por visiÃ³n para robot UR5 con gripper Robotiq en ROS 2 Humble.

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#descripciÃ³n-general)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Requisitos](#requisitos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso](#uso)
- [Componentes](#componentes)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Troubleshooting](#troubleshooting)
- [Desarrollo Futuro](#desarrollo-futuro)

---

## ğŸ¯ DescripciÃ³n General

Este proyecto implementa un sistema completo de manipulaciÃ³n robÃ³tica que integra:

- âœ… **DetecciÃ³n visual de objetos** por color (RGB-D camera)
- âœ… **TransformaciÃ³n de coordenadas** (pÃ­xel â†’ 3D â†’ frame del robot)
- âœ… **PlanificaciÃ³n de movimientos** con MoveIt 2
- âœ… **Control del brazo robÃ³tico** UR5 (6 DOF)
- âœ… **Control del gripper** Robotiq 85
- âœ… **SimulaciÃ³n completa** en Gazebo

### Flujo del Sistema

```
ğŸ“· CÃ¡mara RGB-D
    â†“
ğŸ” DetecciÃ³n de objetos (OpenCV)
    â†“
ğŸ“ Coordenadas 3D (PointCloud â†’ TF)
    â†“
ğŸ“¡ PublicaciÃ³n en /detected_objects
    â†“
ğŸ§  PlanificaciÃ³n con MoveIt
    â†“
ğŸ¤– EjecuciÃ³n en UR5
    â†“
âœ‹ Control del gripper
```

---

## ğŸ—ï¸ Arquitectura del Sistema

### Hardware (Simulado)
- **Robot:** Universal Robots UR5 (6 DOF)
- **Gripper:** Robotiq 85
- **Sensor:** CÃ¡mara RGB-D (tipo Kinect)
- **Entorno:** Gazebo con world2 personalizado

### Software Stack
- **ROS 2:** Humble
- **SimulaciÃ³n:** Gazebo Classic
- **PlanificaciÃ³n:** MoveIt 2
- **VisiÃ³n:** OpenCV + sensor_msgs
- **Control:** ros2_control

### Nodos Principales

| Nodo | FunciÃ³n | Topics Pub/Sub |
|------|---------|----------------|
| `vision_detector` | Detecta objetos y calcula posiciones 3D | Pub: `/detected_objects`, `/object_markers` |
| `robot_mover_action` | Control del brazo con MoveIt | Sub: `/joint_states`, Action: `/move_action` |
| `gripper_controller` | Control del gripper Robotiq | Action: `/gripper_position_controller/gripper_cmd` |
| `pick_place_main` | Coordinador del pipeline completo | Sub: `/detected_objects` |

---

## ğŸ“¦ Requisitos

### Sistema Operativo
- Ubuntu 22.04 LTS

### ROS 2
```bash
# ROS 2 Humble
sudo apt install ros-humble-desktop-full
sudo apt install ros-humble-moveit
sudo apt install ros-humble-ros2-control
sudo apt install ros-humble-ros2-controllers
sudo apt install ros-humble-gazebo-ros-pkgs
```

### Dependencias Python
```bash
# OpenCV y CV Bridge
sudo apt install ros-humble-cv-bridge python3-opencv

# Scipy (para transformaciones)
pip3 install scipy

# Sensor messages
sudo apt install ros-humble-sensor-msgs-py
```

### Paquetes del Proyecto
- `ur_yt_sim` - SimulaciÃ³n y configuraciÃ³n del robot
- `ur5_camera_gripper_moveit_config` - ConfiguraciÃ³n de MoveIt
- `ur5_pick_place` - Scripts de control y visiÃ³n

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
cd ~/misCosas/ros2_ws/src
git clone <URL_DEL_REPO> LearnRoboticsWROS
```

### 2. Instalar Dependencias

```bash
cd ~/misCosas/ros2_ws
rosdep install --from-paths src --ignore-src -r -y
```

### 3. Compilar

```bash
cd ~/misCosas/ros2_ws
colcon build
source install/setup.bash
```

### 4. Verificar InstalaciÃ³n

```bash
# Listar paquetes instalados
ros2 pkg list | grep ur

# DeberÃ­a mostrar:
# - ur_yt_sim
# - ur5_camera_gripper_moveit_config
# - ur5_pick_place
```

---

## ğŸ® Uso

### Lanzar el Sistema Completo

#### Terminal 1: SimulaciÃ³n + MoveIt
```bash
cd ~/misCosas/ros2_ws
source install/setup.bash
ros2 launch ur_yt_sim spawn_ur5_camera_gripper_moveit.launch.py
```

**Esto inicia:**
- âœ… Gazebo con world2
- âœ… Robot UR5 con gripper
- âœ… CÃ¡mara RGB-D
- âœ… MoveIt con RViz
- âœ… Controladores (brazo + gripper)

#### Terminal 2: Sistema de VisiÃ³n
```bash
cd ~/misCosas/ros2_ws/src/LearnRoboticsWROS/ur_yt_sim/scripts
python3 vision_detector.py
```

**Esto publica:**
- `/detected_objects` - JSON con objetos y posiciones 3D
- `/object_poses` - PoseArray para MoveIt
- `/object_markers` - Marcadores para RViz

#### Terminal 3: Control del Robot
```bash
cd ~/misCosas/ros2_ws/src/LearnRoboticsWROS/ur5_pick_place/scripts/API_moveit
python3 robot_mover_action.py
```

**MenÃº interactivo:**
```
1. Mover a HOME
2. Mover a ZERO
3. Mover a UP
```

---

## ğŸ§© Componentes

### 1. Sistema de VisiÃ³n (`vision_detector.py`)

**Funcionalidad:**
- Detecta objetos de colores: rojo, azul, verde, amarillo, naranja
- Obtiene coordenadas 3D desde la imagen de profundidad
- Transforma coordenadas de `camera_link` a `base_link`
- Publica resultados en formato JSON y marcadores 3D

**ConfiguraciÃ³n:**
```python
# Rangos de color HSV (modificables)
'red': [(0, 100, 100), (10, 255, 255)]
'green': [(40, 100, 100), (80, 255, 255)]
'blue': [(100, 100, 100), (130, 255, 255)]
```

**Topics:**
- `/detected_objects` (String/JSON)
- `/object_poses` (PoseArray)
- `/object_markers` (MarkerArray)

**Ejemplo de salida:**
```json
[
  {
    "id": 0,
    "color": "green",
    "pixel_x": 320,
    "pixel_y": 240,
    "area": 1234.5,
    "position_camera_frame": {"x": 0.456, "y": 0.123, "z": 0.852},
    "position_robot_frame": {"x": 0.523, "y": -0.034, "z": 1.652}
  }
]
```

---

### 2. Control del Robot (`robot_mover_action.py`)

**Funcionalidad:**
- Usa Move Action API (mismo que RViz)
- Mueve a poses predefinidas (home, zero, up)
- PlanificaciÃ³n y ejecuciÃ³n con MoveIt
- Control preciso de velocidad y aceleraciÃ³n

**Poses Predefinidas:**
```python
"home": [0.0, -2.2564, 1.4059, -1.6315, -1.57, 0.0]
"zero": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
"up": [0.0, -1.57, 0.0, -1.57, 0.0, 0.0]
```

**ParÃ¡metros de Movimiento:**
- `max_velocity_scaling_factor`: 0.1 (10% velocidad mÃ¡xima)
- `max_acceleration_scaling_factor`: 0.1 (10% aceleraciÃ³n mÃ¡xima)
- `allowed_planning_time`: 5.0 segundos
- `num_planning_attempts`: 10

---

### 3. CÃ¡mara RGB-D

**Especificaciones:**
- **Tipo:** Depth camera (RGB + profundidad)
- **ResoluciÃ³n:** 640x480 pÃ­xeles
- **Frecuencia:** 10 Hz
- **Campo de visiÃ³n:** 62.4Â° horizontal
- **Rango:** 5cm - 8m
- **PosiciÃ³n:** Fija a 1.2m altura, mirando hacia abajo

**Topics:**
- `/camera/image_raw` - Imagen RGB
- `/camera/depth/image_raw` - Mapa de profundidad
- `/camera/points` - Nube de puntos 3D
- `/camera/camera_info` - ParÃ¡metros intrÃ­nsecos

**Modificar posiciÃ³n:**
```bash
nano ~/misCosas/ros2_ws/src/LearnRoboticsWROS/ur_yt_sim/urdf/camera.xacro
# LÃ­nea 36: <origin xyz="0.5 0 1.2" rpy="0 1.57 0"/>
```

---

### 4. Control del Gripper

**Especificaciones:**
- **Modelo:** Robotiq 85
- **Apertura:** 0 - 85mm
- **Joint principal:** `robotiq_85_left_knuckle_joint`
- **Posiciones:** Abierto (0.0) / Cerrado (0.79)

**Action:**
```bash
/gripper_position_controller/gripper_cmd
```

**Uso desde Python:**
```python
from control_msgs.action import GripperCommand

goal = GripperCommand.Goal()
goal.command.position = 0.0  # Abierto
goal.command.max_effort = 100.0
```

---

## ğŸ“ Estructura del Proyecto

```
LearnRoboticsWROS/
â”œâ”€â”€ ur_yt_sim/                           # Paquete principal de simulaciÃ³n
â”‚   â”œâ”€â”€ launch/
â”‚   â”‚   â””â”€â”€ spawn_ur5_camera_gripper_moveit.launch.py
â”‚   â”œâ”€â”€ urdf/
â”‚   â”‚   â”œâ”€â”€ ur.urdf.xacro                # URDF principal
â”‚   â”‚   â””â”€â”€ camera.xacro                 # ConfiguraciÃ³n de cÃ¡mara
â”‚   â”œâ”€â”€ worlds/
â”‚   â”‚   â””â”€â”€ world2.world                 # Mundo con objetos
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ ur5_controllers.yaml         # ConfiguraciÃ³n controladores
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ vision_detector.py           # Sistema de visiÃ³n
â”‚
â”œâ”€â”€ ur5_camera_gripper_moveit_config/    # ConfiguraciÃ³n MoveIt
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ ur.srdf                      # SemÃ¡ntica del robot
â”‚   â”‚   â”œâ”€â”€ moveit_controllers.yaml     # Controladores MoveIt
â”‚   â”‚   â”œâ”€â”€ kinematics.yaml              # CinemÃ¡tica (IK/FK)
â”‚   â”‚   â””â”€â”€ moveit.rviz                  # ConfiguraciÃ³n RViz
â”‚   â””â”€â”€ launch/
â”‚       â””â”€â”€ moveit.launch.py
â”‚
â””â”€â”€ ur5_pick_place/                      # Scripts de control
    â””â”€â”€ scripts/
        â””â”€â”€ API_moveit/
            â”œâ”€â”€ robot_mover_action.py    # Control del robot
            â””â”€â”€ gripper_controller.py    # Control del gripper (futuro)
```

---

## ğŸ”§ ConfiguraciÃ³n

### Archivos Clave

#### 1. SRDF - ConfiguraciÃ³n SemÃ¡ntica
**UbicaciÃ³n:** `ur5_camera_gripper_moveit_config/config/ur.srdf`

**Planning Groups:**
- `ur5_manipulator` - Brazo (6 DOF)
- `robotiq_gripper` - Gripper

**Poses Predefinidas:**
- `home`, `zero`, `up` (brazo)
- `open`, `close` (gripper)

#### 2. Controllers - ConfiguraciÃ³n de Control
**UbicaciÃ³n:** `ur5_camera_gripper_moveit_config/config/moveit_controllers.yaml`

```yaml
joint_trajectory_controller:
  type: FollowJointTrajectory
  joints:
    - shoulder_pan_joint
    - shoulder_lift_joint
    - elbow_joint
    - wrist_1_joint
    - wrist_2_joint
    - wrist_3_joint

gripper_position_controller:
  type: GripperCommand
  joints:
    - robotiq_85_left_knuckle_joint
```

#### 3. World - Entorno de SimulaciÃ³n
**UbicaciÃ³n:** `ur_yt_sim/worlds/world2.world`

**Contiene:**
- Mesa de trabajo (1.2m x 1.2m)
- Objetos de colores para agarrar
- IluminaciÃ³n
- FÃ­sica configurada

---

## ğŸ¨ VisualizaciÃ³n en RViz

### Agregar Marcadores de Objetos

1. En RViz, clic en **"Add"**
2. Seleccionar **"MarkerArray"**
3. Topic: `/object_markers`
4. âœ… VerÃ¡s esferas de colores en las posiciones de los objetos

### Ver Imagen de CÃ¡mara

1. Clic en **"Add"**
2. Seleccionar **"Image"**
3. Topic: `/camera/image_raw`

### Ver Nube de Puntos

1. Clic en **"Add"**
2. Seleccionar **"PointCloud2"**
3. Topic: `/camera/points`
4. Color Transformer: **RGB8**

---

## ğŸ§ª Testing

### Verificar CÃ¡mara

```bash
# Ver topics
ros2 topic list | grep camera

# Ver frecuencia
ros2 topic hz /camera/image_raw

# Ver imagen
ros2 run rqt_image_view rqt_image_view
```

### Verificar Controladores

```bash
# Listar controladores
ros2 control list_controllers

# Ver joint states
ros2 topic echo /joint_states --once
```

### Verificar MoveIt

```bash
# Ver si move_group estÃ¡ activo
ros2 node list | grep move_group

# Ver action servers
ros2 action list
```

### Verificar Transformaciones

```bash
# Ver Ã¡rbol TF
ros2 run tf2_tools view_frames
evince frames.pdf

# Ver transformaciÃ³n especÃ­fica
ros2 run tf2_ros tf2_echo base_link camera_link
```

---

## ğŸ› Troubleshooting

### Problema: "Planning failed! Error code: FAILURE"

**Causa:** MoveIt no puede encontrar una trayectoria vÃ¡lida

**Soluciones:**
1. Verificar que el objetivo estÃ¡ dentro del workspace
2. Probar con `num_planning_attempts` mayor
3. Aumentar `allowed_planning_time`
4. Verificar colisiones en RViz

```python
goal_msg.request.num_planning_attempts = 20
goal_msg.request.allowed_planning_time = 10.0
```

---

### Problema: CÃ¡mara no detecta objetos

**Verificaciones:**
```bash
# 1. Â¿La cÃ¡mara publica?
ros2 topic hz /camera/image_raw

# 2. Â¿Hay objetos en la escena?
# Verificar en Gazebo

# 3. Â¿Los rangos de color son correctos?
# Ajustar HSV en vision_detector.py
```

**Ajustar rangos HSV:**
```python
# vision_detector.py, lÃ­nea ~65
'green': [(40, 100, 100), (80, 255, 255)]  # Ampliar rango si es necesario
```

---

### Problema: Robot no se mueve desde Python

**Debug:**
```bash
# 1. Â¿Funciona desde RViz?
# Probar "Plan & Execute" en RViz

# 2. Â¿Los controladores estÃ¡n activos?
ros2 control list_controllers

# 3. Â¿El action server responde?
ros2 action send_goal /move_action moveit_msgs/action/MoveGroup "{}"
```

---

### Problema: Transformaciones TF incorrectas

**Verificar:**
```bash
# Ver frames disponibles
ros2 run tf2_tools view_frames

# Ver transformaciÃ³n
ros2 run tf2_ros tf2_echo base_link camera_link

# Debe mostrar:
# Translation: [0.500, 0.000, 1.200]
```

**Corregir en camera.xacro:**
```xml
<origin xyz="0.5 0 1.2" rpy="0 1.57 0"/>
```

---

### Problema: Gazebo se congela

**Causas comunes:**
- FÃ­sica muy pesada
- Demasiados objetos
- GPU insuficiente

**Soluciones:**
```bash
# 1. Reducir calidad grÃ¡fica
export LIBGL_ALWAYS_SOFTWARE=1

# 2. Pausar Gazebo cuando no se usa
# Clic en "Pause" en Gazebo GUI

# 3. Reducir real_time_update_rate en world
# En world2.world:
<real_time_update_rate>500.0</real_time_update_rate>
```

---

## ğŸ“Š ParÃ¡metros Ajustables

### Velocidad del Robot

```python
# En robot_mover_action.py
goal_msg.request.max_velocity_scaling_factor = 0.1  # 0.1 = 10%
goal_msg.request.max_acceleration_scaling_factor = 0.1
```

### DetecciÃ³n de Colores

```python
# En vision_detector.py
color_ranges = {
    'green': [(40, 100, 100), (80, 255, 255)]  # [H_min, S_min, V_min], [H_max, S_max, V_max]
}
```

### Frecuencia de DetecciÃ³n

```python
# En vision_detector.py, lÃ­nea ~45
self.process_rate = 2.0  # Hz (detecciones por segundo)
```

### CÃ¡mara

```xml
<!-- En camera.xacro -->
<update_rate>10</update_rate>  <!-- FPS -->
<horizontal_fov>1.089</horizontal_fov>  <!-- Campo de visiÃ³n en radianes -->
<image><width>640</width><height>480</height></image>  <!-- ResoluciÃ³n -->
```

---

## ğŸš€ Desarrollo Futuro

### Corto Plazo (PrÃ³ximos pasos)
- [ ] Implementar secuencia completa de pick
- [ ] Implementar secuencia completa de place
- [ ] Pipeline automÃ¡tico pick and place
- [ ] Control del gripper integrado

### Mediano Plazo
- [ ] DetecciÃ³n con deep learning (YOLO)
- [ ] EstimaciÃ³n de pose 6D de objetos
- [ ] PlanificaciÃ³n de trayectorias optimizada
- [ ] Manejo robusto de errores

### Largo Plazo
- [ ] MÃºltiples objetos en paralelo
- [ ] ClasificaciÃ³n y sorting por color
- [ ] Apilamiento de objetos
- [ ] Aprendizaje por refuerzo

---

## ğŸ“š Referencias

### DocumentaciÃ³n Oficial
- [ROS 2 Humble](https://docs.ros.org/en/humble/)
- [MoveIt 2](https://moveit.picknik.ai/main/index.html)
- [Gazebo Classic](https://classic.gazebosim.org/)
- [ros2_control](https://control.ros.org/master/index.html)

### Tutoriales Relacionados
- [MoveIt Python API](https://moveit.picknik.ai/main/doc/examples/motion_planning_python_api/motion_planning_python_api_tutorial.html)
- [OpenCV Python](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)
- [TF2 Tutorials](https://docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Tf2-Main.html)

---

## ğŸ‘¥ Contribuciones

Sugerencias para contribuir:
1. Fork del repositorio
2. Crear branch (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push al branch (`git push origin feature/nueva-funcionalidad`)
5. Abrir Pull Request

---

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto bajo licencia [especificar licencia].

---

## ğŸ™ Agradecimientos

- Universal Robots por documentaciÃ³n del UR5
- Robotiq por especificaciones del gripper
- Comunidad de MoveIt
- Comunidad de ROS 2

---

## ğŸ“§ Contacto

Para preguntas o soporte:
- **Email:** [tu email]
- **GitHub:** [tu github]
- **ROS Discourse:** [tu usuario]

---

## ğŸ“ CrÃ©ditos

Proyecto desarrollado como parte de aprendizaje en robÃ³tica y visiÃ³n artificial con ROS 2.

**TecnologÃ­as utilizadas:**
- ROS 2 Humble
- MoveIt 2
- Gazebo Classic
- OpenCV
- Python 3.10
- C++ (URDF/xacro)

---

**Ãšltima actualizaciÃ³n:** Enero 2026  
**VersiÃ³n:** 1.0.0  
**Estado:** En desarrollo activo